{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "<a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n",
    "<a id=\"setup_config\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from /home/user/karacora/lab-vision-systems-assignments/assignment_4/assignment/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import assignment.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kth_gru', 'kth_lstm', 'kth_lstmconv', 'kth_lstmcustom']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.list_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules\n",
    "<a id=\"setup_modules\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import assignment.scripts.init_exp as init_exp\n",
    "from assignment.evaluation.evaluator import Evaluator\n",
    "from assignment.training.trainer import Trainer\n",
    "import assignment.libs.utils_checkpoints as utils_checkpoints\n",
    "import assignment.libs.utils_data as utils_data\n",
    "import assignment.visualization.plot as plot\n",
    "import assignment.visualization.visualize as visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths and names\n",
    "<a id=\"setup_paths_and_names\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_exp_lstm = \"kth_lstm\"\n",
    "name_exp_customlstm = \"kth_customlstm\"\n",
    "name_exp_lstmconv = \"kth_lstmconv\"\n",
    "name_exp_gru = \"kth_lstm\"\n",
    "\n",
    "path_dir_exp_lstm = Path(config._PATH_DIR_EXPS) / name_exp_lstm\n",
    "path_dir_exp_customlstm = Path(config._PATH_DIR_EXPS) / name_exp_customlstm\n",
    "path_dir_exp_lstmconv = Path(config._PATH_DIR_EXPS) / name_exp_lstmconv\n",
    "path_dir_exp_gru = Path(config._PATH_DIR_EXPS) / name_exp_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_exp.init_exp(name_exp=name_exp_lstm, name_config=name_exp_lstm)\n",
    "config.set_config_exp(path_dir_exp_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test, dataloader_test = utils_data.create_dataset_and_dataloader(split=\"test\")\n",
    "images, labels = utils_data.sample(dataloader_test, num_samples=1)\n",
    "\n",
    "path_save = path_dir_exp_lstm / \"visualizations\" / \"Images_test.png\"\n",
    "visualize.visualize_images(images[0], path_save=path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_validate, dataloader_validate = utils_data.create_dataset_and_dataloader(split=\"validate\")\n",
    "images, labels = utils_data.sample(dataloader_validate, num_samples=1)\n",
    "\n",
    "path_save = path_dir_exp_lstm / \"visualizations\" / \"Images_validate.png\"\n",
    "visualize.visualize_images(images[0], path_save=path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataloader_train = utils_data.create_dataset_and_dataloader(split=\"train\")\n",
    "images, labels = utils_data.sample(dataloader_train, num_samples=1)\n",
    "\n",
    "path_save = path_dir_exp_lstm / \"visualizations\" / \"Images_train.png\"\n",
    "visualize.visualize_images(images[0], path_save=path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing experiment kth_lstm...\n",
      "Created directory /home/user/karacora/lab-vision-systems-assignments/assignment_4/experiments/kth_lstm\n",
      "Created directory /home/user/karacora/lab-vision-systems-assignments/assignment_4/experiments/kth_lstm/checkpoints\n",
      "Created directory /home/user/karacora/lab-vision-systems-assignments/assignment_4/experiments/kth_lstm/logs\n",
      "Created directory /home/user/karacora/lab-vision-systems-assignments/assignment_4/experiments/kth_lstm/tensorboard\n",
      "Created directory /home/user/karacora/lab-vision-systems-assignments/assignment_4/experiments/kth_lstm/plots\n",
      "Created directory /home/user/karacora/lab-vision-systems-assignments/assignment_4/experiments/kth_lstm/visualizations\n",
      "Config loaded from /home/user/karacora/lab-vision-systems-assignments/assignment_4/assignment/configs/kth_lstm.yaml\n",
      "Config saved to /home/user/karacora/lab-vision-systems-assignments/assignment_4/experiments/kth_lstm/config.yaml\n",
      "Initializing experiment kth_lstm finished\n",
      "Config loaded from /home/user/karacora/lab-vision-systems-assignments/assignment_4/experiments/kth_lstm/config.yaml\n"
     ]
    }
   ],
   "source": [
    "init_exp.init_exp(name_exp=name_exp_lstm, name_config=name_exp_lstm)\n",
    "config.set_config_exp(path_dir_exp_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up dataloaders...\n",
      "Train dataset\n",
      "Dataset KTH\n",
      "    Number of datapoints: 4469\n",
      "    Path: /home/user/karacora/lab-vision-systems-assignments/assignment_4/data/kth\n",
      "    Split: train\n",
      "    Transform: Compose(\n",
      "      ToDtype(\n",
      "    scale=True\n",
      "    (transform_tv): ToDtype(scale=True)\n",
      "  )\n",
      "      RandomHorizontalFlip(p=0.5)\n",
      "      RandomRotation(degrees=[-10.0, 10.0], interpolation=InterpolationMode.NEAREST, expand=False, fill=0)\n",
      "      ColorJitter(brightness=(0.5, 1.5), contrast=(0.8, 1.2))\n",
      "      GaussianNoise()\n",
      "      Clip(min=0.0, max=1.0)\n",
      ")\n",
      "    Transform of target: None\n",
      "Validate dataset\n",
      "Dataset KTH\n",
      "    Number of datapoints: 4332\n",
      "    Path: /home/user/karacora/lab-vision-systems-assignments/assignment_4/data/kth\n",
      "    Split: validate\n",
      "    Transform: ToDtype(\n",
      "  scale=True\n",
      "  (transform_tv): ToDtype(scale=True)\n",
      ")\n",
      "    Transform of target: None\n",
      "Setting up dataloaders finished\n",
      "Setting up model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RNNClassifier.__init__() got an unexpected keyword argument 'kwargs_lstm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_exp_lstm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mloop(config\u001b[38;5;241m.\u001b[39mTRAINING[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m log \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mlog\n",
      "File \u001b[0;32m~/lab-vision-systems-assignments/assignment_4/assignment/training/trainer.py:36\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, name_exp, quiet)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquiet \u001b[38;5;241m=\u001b[39m quiet\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/lab-vision-systems-assignments/assignment_4/assignment/training/trainer.py:71\u001b[0m, in \u001b[0;36mTrainer._init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatches\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     },\n\u001b[1;32m     68\u001b[0m }\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_dataloaders()\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_optimizer()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_criterion()\n",
      "File \u001b[0;32m~/lab-vision-systems-assignments/assignment_4/assignment/training/trainer.py:97\u001b[0m, in \u001b[0;36mTrainer.setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting up model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m class_model \u001b[38;5;241m=\u001b[39m utils_import\u001b[38;5;241m.\u001b[39mimport_model(config\u001b[38;5;241m.\u001b[39mMODEL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mclass_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransfer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mMODEL:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# Won't stay like this. Assume we start with epoch 0 for now.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs_freeze\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mMODEL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransfer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mMODEL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransfer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs_freeze\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: RNNClassifier.__init__() got an unexpected keyword argument 'kwargs_lstm'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(name_exp_lstm)\n",
    "trainer.loop(config.TRAINING[\"num_epochs\"])\n",
    "log = trainer.log\n",
    "\n",
    "path_plots = path_dir_exp_lstm / \"plots\"\n",
    "plot.plot_loss(log, path_save=path_plots / \"Loss.pdf\")\n",
    "plot.plot_metrics(log, path_save=path_plots / \"Metrics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model, _, _ = utils_checkpoints.load(path_dir_exp_lstm / \"checkpoints\" / \"final.pth\")\n",
    "\n",
    "evaluator = Evaluator(name_exp_lstm, model)\n",
    "evaluator.evaluate()\n",
    "\n",
    "print(f\"Loss on test data: {evaluator.log[\"total\"][\"loss\"]}\")\n",
    "print(f\"Metrics on test data\")\n",
    "for name, metrics in evaluator.log[\"total\"][\"metrics\"].items():\n",
    "    print(f\"    {name:<10}: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_exp.init_exp(name_exp=name_exp_customlstm, name_config=name_exp_customlstm)\n",
    "config.set_config_exp(path_dir_exp_customlstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(name_exp_customlstm)\n",
    "trainer.loop(config.TRAINING[\"num_epochs\"])\n",
    "log = trainer.log\n",
    "\n",
    "path_plots = path_dir_exp_customlstm / \"plots\"\n",
    "plot.plot_loss(log, path_save=path_plots / \"Loss.pdf\")\n",
    "plot.plot_metrics(log, path_save=path_plots / \"Metrics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model, _, _ = utils_checkpoints.load(path_dir_exp_customlstm / \"checkpoints\" / \"final.pth\")\n",
    "\n",
    "evaluator = Evaluator(name_exp_customlstm, model)\n",
    "evaluator.evaluate()\n",
    "\n",
    "print(f\"Loss on test data: {evaluator.log[\"total\"][\"loss\"]}\")\n",
    "print(f\"Metrics on test data\")\n",
    "for name, metrics in evaluator.log[\"total\"][\"metrics\"].items():\n",
    "    print(f\"    {name:<10}: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_exp.init_exp(name_exp=name_exp_lstmconv, name_config=name_exp_lstmconv)\n",
    "config.set_config_exp(path_dir_exp_lstmconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(name_exp_lstmconv)\n",
    "trainer.loop(config.TRAINING[\"num_epochs\"])\n",
    "log = trainer.log\n",
    "\n",
    "path_plots = path_dir_exp_lstmconv / \"plots\"\n",
    "plot.plot_loss(log, path_save=path_plots / \"Loss.pdf\")\n",
    "plot.plot_metrics(log, path_save=path_plots / \"Metrics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model, _, _ = utils_checkpoints.load(path_dir_exp_lstmconv / \"checkpoints\" / \"final.pth\")\n",
    "\n",
    "evaluator = Evaluator(name_exp_lstmconv, model)\n",
    "evaluator.evaluate()\n",
    "\n",
    "print(f\"Loss on test data: {evaluator.log[\"total\"][\"loss\"]}\")\n",
    "print(f\"Metrics on test data\")\n",
    "for name, metrics in evaluator.log[\"total\"][\"metrics\"].items():\n",
    "    print(f\"    {name:<10}: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_exp.init_exp(name_exp=name_exp_gru, name_config=name_exp_gru)\n",
    "config.set_config_exp(path_dir_exp_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(name_exp_gru)\n",
    "trainer.loop(config.TRAINING[\"num_epochs\"])\n",
    "log = trainer.log\n",
    "\n",
    "path_plots = path_dir_exp_gru / \"plots\"\n",
    "plot.plot_loss(log, path_save=path_plots / \"Loss.pdf\")\n",
    "plot.plot_metrics(log, path_save=path_plots / \"Metrics.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, model, _, _ = utils_checkpoints.load(path_dir_exp_gru / \"checkpoints\" / \"final.pth\")\n",
    "\n",
    "evaluator = Evaluator(name_exp_gru, model)\n",
    "evaluator.evaluate()\n",
    "\n",
    "print(f\"Loss on test data: {evaluator.log[\"total\"][\"loss\"]}\")\n",
    "print(f\"Metrics on test data\")\n",
    "for name, metrics in evaluator.log[\"total\"][\"metrics\"].items():\n",
    "    print(f\"    {name:<10}: {metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
